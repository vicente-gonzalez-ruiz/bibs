@Article{rosenblatt1958perceptron,
  author = {Rosenblatt, F.},
  title = {The perceptron: a probabilistic model for information storage and organization in the brain},
  journal = {Psychological review},
  year = {1958},
  volume = {65},
  number = 6},
  pages = {386}
}

@Article{rumelhart86learning,
  author = {Rumelhart, D.E. and
            Hinton, G.E. and
	    Williams, R.J.},
  title	= {{Learning Representations by Back-Propagating Erros}},
  journal = {Nature},
  year = {1986},
  volume = {323},
  pages	= {533-536}
}

@Article{lippman87introduction,
  author = {Lippman, R.},
  title	= {{An Introduction to Computing with Neural Nets}},
  journal = {IEEE ASSP Magazine},
  year = {1987},
  volume = {3},
  number = {4},
  pages	= {4-22}
}

@Article{burton98net,
  author = {Burton, K. and
            Farkas, D.L.},
  title	= {{Net Progress}},
  journal = {Nature},
  year = {1998},
  volume = {391},
  pages	= {540-541}
}

@Article{jiang1999image,
  author = {Jiang, J.},
  title = {Image compression with neural networks -- A survey},
  journal = {Signal processing: image Communication},
  year = {1999},
  volume = {14},
  number = {9},
  publisher = {Elsevier},
  note = {image (pixels) -> | transform | -> transformed image (coeffs) -> | Quantization | -> quantized transformed image (bins) -> | Entropy Coding | -> compressed image code-stream (code-words). A. Direct NN for image compression. A.1. Back-propagation learning based. A.2. Hebbian learning based. A.3. VQ based. B. NN using existing technology. B.1 Wavelet optimization kernel. B.2. Fractal NN. 3. NN-based predictive coding (DPCM). Narrow channel neural network codec. Several hidden later can exploit the correlation at different resolutions.}
}

@InProceedings{erdogmus2001entropy,
  author = {Erdogmus, D. and
            Principe, J.C.},
  title = {Entropy Minimization Algorithm for Multilayer Perceptrons},
  booktitle = {International Joint Conference on Neural Networks},
  year = {2001}
  volume = {4},
  pages = {3003--3008},
  organization = {IEEE}
}

@TechReport{krizhevsky2009learning,
  author = {Krizhevsky, A.},
  title = {Learning Multiple Layers of Features from Tiny Images},
  institution = {Citeseer},
  year = {2009}
}

@InProceedings{glorot2010understanding,
  author = {Glorot, X. and
            Bengio, Y.},
  title = {Understanding the difficulty of training deep feedforward neural networks},
  booktitle = {International Conference on Artificial Intelligence and Statistics},
  year = {2010},
  pages = {249--256},
}

@InProceedings{goodfellow2014generative,
  author = {Goodfellow, I. and
            Pouget-Abadie, J. and
	    Mirza, M. and
	    Xu, B. and
	    Warde-Farley, D. and
	    Ozair, S. and
	    Courville, A. and
	    Bengio, Y.},
  title = {Generative Adversarial Nets},
  booktitle = {Advances in neural information processing systems},
  year = {2014},
  pages = {2672--2680}
}

@InProceedings{simonyan2014very,
  author = {Simonyan, K. and
            Zisserman, A.},
  title = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  booktitle = {International Conference on Learning Representations},
  year = {2015},
  pages = {1150--1210}
}

@InProceedings{babu2015hyperspectral,
  author = {Babu, K.S. and
            Ramachandran, V. and
	    Thyagharajan, K.K. and
	    Santhosh, G.},
  title = {Hyperspectral Image Compression Algorithms – A Review},
  booktitle = {Artificial Intelligence and Evolutionary Algorithms in Engineering Systems},
  year = {2015},
  pages = {127--138},
  publisher = {Springer},
  note = {A HSI can be regarded as a stack of individual images of the same spatial scene. Each pixel records the intensity at different wavelengths of the electromagnetic spectrum reflected by a specific area. Unnecessary information for the analysis process can be removed by the lossy codec.}
}

@InProceedings{masalmah2015framework,
  author = {Masalmah, Y.M. and
            Mart{\'\i}nez Nieves, C. and
	    Rivera Soto, R. and
	    Velez, C. and
	    Gonzalez, J.},
  title = {A Framework of Hyperspectral Image Compression using Neural Networks},
  booktitle = {Latin American and Caribbean Conference for Engineering and Technology Proceedings},
  year = {2015},
  number = 	 {13},
  organization = {Univ. del Turabo (Puerto Rico)},
  note = {Algunas notas: each pixel (vector) has an associated spectral signature. We have thousands of spectral bands (GB/image). Artificial Neural Networks ignore noise and learn information. The results of the compressed analysis should be similar to those of the normal analysis process. No se explota la redundancia entre bandas de frecuencia. Uan un MLP con 3 capas y la capa oculta con menos neuronas que las en entrada y salida.}
}

@InProceedings{he2016deep,
  author = {He, K. and
            Zhang, X. and
	    Ren, S. and
	    Sun, J.},
  title = {Deep Residual Learning for Image Recognition},
  booktitle = {IEEE conference on computer vision and pattern recognition},
  year = {2016},
  pages = {770--778}
}

@TechReport{goodfellow2016nips,
  author = {Goodfellow, I.},
  title = {NIPS 2016 Tutorial: Generative Adversarial Networks},
  institution = {arXiv preprint arXiv:1701.00160},
  year = 2016}
}

@InProceedings{gregor2016towards,
  author = {Gregor, K. and
           Besse, F. and
	   Rezende, D.J. and
	   Danihelka, I. and
	   Wierstra, D.},
  title = {Towards Conceptual Compression},
  booktitle = {Advances In Neural Information Processing System},
  year = {2016},
  pages = {3549--3557}
}

@InProceedings{rippel2017real,
  author = {Rippel, O. and
            Bourdev, L.},
  title = {Real-time adaptive image compression},
  booktitle = {International Conference on Machine Learning},
  year = {2017},
  pages = {2922--2930},
  note = {No aclaran mucho el algoritmo que usan (pertenencen a OneWave Inc.) pero más o menos usan un CAE (generator) entrenado usando la filosofía de las GANs (con un discriminator). Los resultados son espectaculares. Entiendo que no realizan transformación adaptativa en el dominio de color.}
}

@InProceedings{ledig2017photo,
  author = {Ledig, C. and
            Theis, L. and
	    Husz{\'a}r, F. and
	    Caballero, J. and
	    Cunningham, A. and
	    Acosta, A. and
	    Aitken, A. and
	    Tejani, A. and
	    Totz, J. and
	    Wang, Z. and
	    Shi, W},
  title = {Photo-Realistic Single Image Super-Resolution Using a Generative AdversarialNetwork},
  booktitle = {IEEE conference on computer vision and pattern recognition},
  year = {2017},
  pages = {4681--4690}
}

@Article{krizhevsky2017imagenet,
  author = {Krizhevsky, A. and
            Sutskever, I. and
	    Hinton, G.E.},
  title = {ImageNet Classification with Deep Convolutional Neural Networks},
  journal = {Communications of the ACM},
  year = {2017},
  volume = {60},
  number = {6},
  pages = {84--90}
}

@TechReport{arjovsky2017wasserstein,
  author = {Arjovsky, M. and
            Chintala, S. and
	    Bottou, L.},
  title = {Wasserstein GAN},
  institution = {arXiv preprint arXiv:1701.07875},
  year = {2017}
}

@InProceedings{theis2017lossy,
  author = {Theis, L. and
            Shi, W. and
	    Cunningham, A.
	    and Husz{\'a}r, F.},
  title = {Lossy Image Compression with Compressive Autoencoders},
  booktitle = {International Conference on Learning Representations},
  year = {2017}
}

@Article{jiang2017end,
  author = {Jiang, F. and
            Tao, W. and
	    Liu, S. and
	    Ren, J. and
	    Guo, X. and
	    Zhao, D.},
  title = {An End-to-End Compression Framework Based on Convolutional Neural Networks},
  journal = {Transactions on Circuits and Systems for Video Technology},
  year = {2017},
  volume = {28},
  number = {10},
  pages = {3007--3018},
  note = {The aim of image compression is to reduce irrelevance and redundancy of an image in order to store or transimit the image at low bit rates.}
}

@InProceedings{balle2016end,
  author = {Ball{\'e}, J. and
            Laparra, V. and
	    Simoncelli, E.P.},
  title = {End-to-end Optimized Image Compression},
  booktitle = {International Conference on Learning Representations},
  year = {2017}
}

@Article{jiang2017end,
  author = {Jiang, F. and
            Tao, W. and
	    Liu, S. and
	    Ren, J. and
	    Guo, X. and
	    Zhao, D.},
  title = {An End-to-End Compression Framework Basedon Convolutional Neural Networks},
  journal = {Transactions on Circuits and Systems for Video Technology},
  year = {2017},
  volume = {28},
  number = {10},
  pages = {3007--3018}
  note = {Crean un compresor basado en dos CNNs y un compresor de imágenes (que puede ser JPEG, JPEG2000 o BPG). Las imágenes son tratadas previamente con una CNN que genera una imagen específica para el compresor de imágenes, que es comprimida con el compresor de imagenes y luego, usan la otra CNN para restaurar la imagen original. Todo el sistema es optimizado para cada compresor de imágenes específico.}
}

@InProceedings{toderici2017full,
  author = {Toderici, G. and
            Vincent, D. and
	    Johnston, N. and
	    Hwang, S.J. and
	    Minnen, D. and
	    Shor, J. and
	    Covell, M.},
  title = {Full Resolution Image Compression with Recurrent Neural Networks},
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year = {2017},
  pages = {5306--5314}
}

@InProceedings{cheng2018deep,
  author = {Cheng, Z. and
            Sun, H. and
	    Takeuchi, M. and
	    Katto, J.},
  title = {Deep Convolutional AutoEncoder-based LossyImage Compression},
  booktitle = {Picture Coding Symposium},
  year = {2018},
  pages = {253--257},
  note = {Un CAE (Convolutional AutoEncoder) sigue la filosofía de un MLP (MultiLayer Perceptron) de canal estrecho, pero usa CNNs en lugar de simples capas de neuronas. En este trabajo, se plantea un CAE para comprimir imágenes en blanco y negro (entrenado sólo con la luma de las imágenes en color). El code stream es el resultado de usar J2K a los autovectores (PCA) de los mapas de características generados por la primera mitad del CAE. Se usan patches de 128x128 pixels. Los resultados son buenos, aunque los propios autores comentan que usando GANs podrían mejorarse.}
}

@InProceedings{santurkar2018generative,
  author = {Santurkar, S. and
            Budden, D. and
	    Shavit, N.},
  title = {Generative Compression},
  booktitle = {Picture Coding Symposium (PCS)},
  year = {2018},
  pages = {258--262},
  organization = {IEEE}
}

@InProceedings{choi2019variable,
  author = {Choi, Y. and
            El-Khamy, M.
	    and Lee, J.},
  title = {Variable rate deep image compression with a conditional autoencoder},
  booktitle = {International Conference on Computer Vision},
  year = {2019},
  editor = {IEEE},
  pages = {3146--3154},
}

@Article{wang2019end,
  author = {Wang, C. and
            Han, Y. and
	    Wang, W.},
  title = {An End-to-End Deep Learning Image Compression Framework Based on Semantic Analysis},
  journal = {Applied Sciences},
  year = {2019},
  volume = {9},
  number = {17},
  pages = {3580+13},
  note = {Usan semantic analysis para decidir el CR de cada pixel de
                  la imagen y a continuación comprimen las imágenes
                  con la red neuronal recurrente de Toderici.}
}

@InProceedings{adate2019analysing,
  author = {},
  title = {Adate, A. and
           Saxena, R. and
	   Kiruba, B.G.G.},
  booktitle = {Soft Computing for Problem Solving},
  year = {2019},
  pages = {425--432},
  publisher = {Springer},
  note = {Este es un paper raro. No me entero. Además, los resultados no tienen sentido (el PSNR aumenta con el CR).}
}

@Article{valsesia2019high,
  author = {Valsesia, D. and
            Magli, E.},
  title = {High-throughput Onboard Hyperspectral Image Compression with Ground-based CNN Reconstruction},
  journal = {Transactions on Geoscience and Remote Sensing},
  year = {2019},
  volume = {57},
  number = {12},
  pages = {9544--9553},
  publisher = {IEEE},
  note = {Proponen modificar el estándar CCSDS (Consultative Committee for Space Data Systems (CCSDS) 123.0-B-1 sacando el cuantificador del lazo DPCM y poniéndolo tras la fase de predicción. Esto aumenta el throughput por 4 aproximadamente para el mismo consumo (estamos pensando en que esto se instala en un satélite) pero empeora la curva RD. Para mitigar este efecto, proponen usar una CNN en tierra que incrementa la calidad, obteniendo una comparable a la que se obtendría dejando el cuantificador dentro del lazo.}
}

@InProceedings{aidini2019hyperspectral,
  author = {Aidini, A. and
            Giannopoulos, M. and
	    Pentari, A. and
	    Fotiadou, K. and
	    Tsakalides, P.},
  title = {Hyperspectral Image Compression and Super-Resolution Using Tensor Decomposition Learning},
  booktitle = {53rd Asilomar Conference on Signals, Systems, and Computers},
  year = {2019},
  pages = {1369--1373},
  organization = {IEEE}
  note = {En realidad este no es un paper de compresión de imágenes hiperespectrales usando ANNs, sino un paper de restauración de imágenes hiperespetrales (usando ANNs) que no poseen la resolución espacial ni el rango dinámico necesarios para su posterior análisis. De hecho, ni siquiera usan un compresor. Simplemente cuantifican las muestras y submuestrean las imágenes para luego ver si las pueden "recuperar" desde el punto de vista de la clasificación.}
}

@Article{dua2020comprehensive,
  author = {Dua, Y. and
            Kumar, V. and
	    Singh, R.S.},
  title = {Comprehensive review of hyperspectral imagecompression algorithms},
  journal = {Optical Engineering},
  year = {2020},
  volume = {59},
  number = {9},
  pages = {090902-1--090902-39},
  note = {Sensors collect data in contiguous band of wavelength raging from 400 to 2500 nm. Each band (spectral resolution) has the same number of pixels (spatial resolution). Each pixel collects reflectance value of a spatial area for different wavelengths. Military, agricultural, industry (terrestial and spacial). For example, the AVIRIS sensor captures HSI of 614*500 pixels, with 224 components (unos 131 MB/image). HSIs have statistical and analytical redudancy (we have an excess of information in the images). There are standards: CCSDS (Consultative Committee for Space Data Systems), Posiblidades: lossless/near-lossless/lossy. On-boards compression VS data-center compression.}
}

@article{dosovitskiy2020image,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, A. and
          Beyer, L. and
	  Kolesnikov, A. and
	  Weissenborn, D. and
	  Zhai, X. and
	  Unterthiner, T. and
	  Dehghani, M. and
	  Minderer, M. and
	  Heigold, G. and
	  Gelly, S. and
	  Uszkoreit, J. and
	  Houlsby, N.},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}
